pub mod api;
pub mod app;
pub mod archive;
pub mod handler;
pub mod markdown;
pub mod model;
pub mod render;
pub mod theme;
pub mod tools;
pub mod ui;

use crate::command::chat::theme::ThemeName;
use crate::config::YamlConfig;
use crate::{error, info};
use api::call_openai_stream;
use handler::run_chat_tui;
use model::{
    AgentConfig, ChatMessage, ModelProvider, agent_config_path, load_agent_config,
    save_agent_config,
};
use std::io::{self, Write};

pub fn handle_chat(content: &[String], _config: &YamlConfig) {
    let agent_config = load_agent_config();

    if agent_config.providers.is_empty() {
        info!("‚ö†Ô∏è  Â∞öÊú™ÈÖçÁΩÆ LLM Ê®°ÂûãÊèê‰æõÊñπ„ÄÇ");
        info!("üìÅ ËØ∑ÁºñËæëÈÖçÁΩÆÊñá‰ª∂: {}", agent_config_path().display());
        info!("üìù ÈÖçÁΩÆÁ§∫‰æã:");
        let example = AgentConfig {
            providers: vec![ModelProvider {
                name: "GPT-4o".to_string(),
                api_base: "https://api.openai.com/v1".to_string(),
                api_key: "sk-your-api-key".to_string(),
                model: "gpt-4o".to_string(),
            }],
            active_index: 0,
            system_prompt: Some("‰Ω†ÊòØ‰∏Ä‰∏™ÊúâÁî®ÁöÑÂä©Êâã„ÄÇ".to_string()),
            stream_mode: true,
            max_history_messages: 20,
            theme: ThemeName::default(),
            tools_enabled: false,
        };
        if let Ok(json) = serde_json::to_string_pretty(&example) {
            println!("{}", json);
        }
        // Ëá™Âä®ÂàõÂª∫Á§∫‰æãÈÖçÁΩÆÊñá‰ª∂
        if !agent_config_path().exists() {
            let _ = save_agent_config(&example);
            info!(
                "‚úÖ Â∑≤Ëá™Âä®ÂàõÂª∫Á§∫‰æãÈÖçÁΩÆÊñá‰ª∂: {}",
                agent_config_path().display()
            );
            info!("üìå ËØ∑‰øÆÊîπÂÖ∂‰∏≠ÁöÑ api_key ÂíåÂÖ∂‰ªñÈÖçÁΩÆÂêéÈáçÊñ∞ËøêË°å chat ÂëΩ‰ª§");
        }
        return;
    }

    if content.is_empty() {
        // Êó†ÂèÇÊï∞ÔºöËøõÂÖ• TUI ÂØπËØùÁïåÈù¢
        run_chat_tui();
        return;
    }

    // ÊúâÂèÇÊï∞ÔºöÂø´ÈÄüÂèëÈÄÅÊ∂àÊÅØÂπ∂ÊâìÂç∞ÂõûÂ§ç
    let message = content.join(" ");
    let message = message.trim().to_string();
    if message.is_empty() {
        error!("‚ö†Ô∏è Ê∂àÊÅØÂÜÖÂÆπ‰∏∫Á©∫");
        return;
    }

    let idx = agent_config
        .active_index
        .min(agent_config.providers.len() - 1);
    let provider = &agent_config.providers[idx];

    info!("ü§ñ [{}] ÊÄùËÄÉ‰∏≠...", provider.name);

    let mut messages = Vec::new();
    if let Some(sys) = &agent_config.system_prompt {
        messages.push(ChatMessage::text("system", sys.clone()));
    }
    messages.push(ChatMessage::text("user", message));

    match call_openai_stream(provider, &messages, &mut |chunk| {
        print!("{}", chunk);
        let _ = io::stdout().flush();
    }) {
        Ok(_) => {
            println!(); // Êç¢Ë°å
        }
        Err(e) => {
            error!("\n‚ùå {}", e);
        }
    }
}
